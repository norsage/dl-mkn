{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как не потерять градиент: функции активации, инициализация, нормализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "План на сегодня: разбираем возможные проблемы при обучении\n",
    "1. Инициализация\n",
    "   1. Диагностика проблем:\n",
    "      - начальное распределение выхода\n",
    "      - значения промежуточных активаций и нелинейности с насыщением\n",
    "   2. Настраиваем инициализацию весов\n",
    "2. Нормализация по батчам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Впереди нас ждут разные сложные архитектуры, но перед этим задержимся подольше на MLP, чтобы получить большьше интуитивного понимания об активациях и градиентах в нейронных сетях в процессе обучения\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Подготовим данные, модель и функции для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1. Загружаем MNIST и создаём загрузчики данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    'data', \n",
    "    train=True, \n",
    "    download=True,    \n",
    "    transform=transforms.ToTensor(),\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    'data', \n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2. Задаём архитектуру модели\n",
    "\n",
    "Такая же, как в прошлый раз, но параметры задаём явно и инициализируем значениями из $\\mathcal{N}(0, 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Parameter(torch.randn((input_dim, hidden_dim)), requires_grad=True)\n",
    "        self.b1 = nn.Parameter(torch.randn(hidden_dim), requires_grad=True)\n",
    "        self.w2 = nn.Parameter(torch.randn((hidden_dim, output_dim)), requires_grad=True)\n",
    "        self.b2 = nn.Parameter(torch.randn(output_dim), requires_grad=True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
    "        h = x.flatten(1) @ self.w1 + self.b1\n",
    "        h_act = F.tanh(h)\n",
    "        logits = h_act @ self.w2 + self.b2\n",
    "        # помимо логитов, вернём ещё промежуточные активации - они нам понадобятся\n",
    "        return logits, h_act, h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.3. Определим функции обучения\n",
    "\n",
    "Всё как обычно, но\n",
    "1. градиенты обновляем вручную\n",
    "2. эпоху ограничиваем сотней батчей - просто для скорости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(batch: tuple[torch.Tensor, torch.Tensor], model: MLP, lr: float = 0.01) -> torch.Tensor:\n",
    "    # прогоняем батч через модель\n",
    "    x, y = batch\n",
    "    logits, *_ = model(x)\n",
    "    # оцениваем значение ошибки\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    # обновляем параметры\n",
    "    loss.backward()\n",
    "    for param in model.parameters():\n",
    "        if param.grad is not None:\n",
    "            param.data -= lr * param.grad\n",
    "        param.grad = None\n",
    "    # возвращаем значение функции ошибки для логирования\n",
    "    return loss\n",
    "\n",
    "def train_epoch(dataloader: DataLoader, model: MLP, lr: float = 0.01, max_batches: int = 100) -> Tensor:\n",
    "    loss_values: list[float] = []\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        loss = training_step(batch, model, lr)\n",
    "        loss_values.append(loss.item())\n",
    "        if i == max_batches:\n",
    "            break\n",
    "    return torch.tensor(loss_values).mean()\n",
    "\n",
    "def test_epoch(dataloader: DataLoader, model: MLP, max_batches: int = 100) -> Tensor:\n",
    "    loss_values: list[float] = []\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        x, y = batch\n",
    "        with torch.no_grad():\n",
    "            logits, *_ = model(x)\n",
    "        # оцениваем значение ошибки\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        loss_values.append(loss.item())\n",
    "        if i == max_batches:\n",
    "            break\n",
    "    return torch.tensor(loss_values).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Инициализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Начальное распределение классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим обучение на несколько эпох и понаблюдаем за изменением ошибки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 12.6718\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "x, y = next(iter(train_loader))\n",
    "input_dim = 784\n",
    "hidden_dim = 128\n",
    "output_dim = len(train_dataset.classes)\n",
    "# создадим модель и выведем значение ошибки после инициализации\n",
    "model = MLP(input_dim, hidden_dim, output_dim)\n",
    "logits, h_act, h = model(x)\n",
    "loss = F.cross_entropy(logits, y)\n",
    "print(f\"Initial loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss = 6.2169\n",
      "Epoch 1 loss = 2.9442\n",
      "Epoch 2 loss = 2.0792\n",
      "Epoch 3 loss = 1.8158\n",
      "Epoch 4 loss = 1.4292\n",
      "Epoch 5 loss = 1.2592\n",
      "Epoch 6 loss = 1.2597\n",
      "Epoch 7 loss = 1.0403\n",
      "Epoch 8 loss = 1.0188\n",
      "Epoch 9 loss = 0.9762\n",
      "Test loss: 1.2467\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batches_per_epoch = 100\n",
    "for i in range(n_epochs):\n",
    "    loss = train_epoch(train_loader, model, lr=0.1, max_batches=batches_per_epoch)\n",
    "    print(f\"Epoch {i} loss = {loss:.4f}\")\n",
    "\n",
    "print(f\"Test loss: {test_epoch(test_loader, model, max_batches=batches_per_epoch):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы стартовали с очень высокого значения ошибки, но уже к третьей эпохе модель сошлась к значению около 2, после чего ошибка уже изменялась понемногу. Почему так?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель очень неоптимально сконфигурирована на этапе инициализации.\n",
    "Начальный лосс очень далёк от ожидаемого - значит, инициализация точно плохая."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А какое ожидаемое значение ошибки?\n",
    "\n",
    "$$CrossEntropy(\\hat{y}, y) = - \\sum_i y_i \\log \\hat{y}_i + (1 - y_i) \\log(1 - \\hat{y}_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3026)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = 10\n",
    "-torch.tensor(1/n_classes).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что же пошло не так?\n",
    "\n",
    "Посмотрим, что происходит с ошибкой в зависимости от значений логитов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0.]), tensor([0.3333, 0.3333, 0.3333]), tensor(1.0986))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = torch.tensor([0., 0., 0.])\n",
    "# logit = torch.randn(3) * 10\n",
    "probs = F.softmax(logit, dim=0)\n",
    "correct = 2\n",
    "\n",
    "logit, probs, -probs[correct].log()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь посмотрим на наши логиты из модели. Что можно сказать о распределении над классами? Что это говорит о нашей инициализации?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  4.1134,   2.9905, -12.1505,  12.8240,  -8.0046,  -2.2303,  -8.9362,\n",
       "        -15.0341,  15.1311,  15.6911], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как нам добиться близости к нулю для логитов?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Упражнение**: Вернёмся в `__init__` модели и зададим инициализацию нулями для `b2` и маленькое стандартное отклонение для `w2`, которое обеспечит нам +- равномерное начальное распределение классов.\n",
    "\n",
    "Изменилось ли значение ошибки, когда мы убрали \"лёгкую часть\" задачи?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Значения промежуточных активаций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.researchgate.net/profile/Rahul-Jayawardana/publication/350567223/figure/fig3/AS:1007855343767554@1617302847631/Fig-3-The-basic-activation-functions-of-the-neural-networksNeural-Networks.jpg\" style=\"background:white\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашей модели мы используем нелинейность `tanh` между линейными слоями.\n",
    "\n",
    "$$\\tanh z = \\frac{e^z - e^{-z}}{e^z + e^{-z}}$$\n",
    "\n",
    "$$\\frac{d(\\tanh z)}{dz} = 1 - \\tanh^2 z$$\n",
    "\n",
    "Что происходит с градиентами при значениях активации близких к $0$? Близких к $1$ и $-1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на активации после нелинейности, применённой на выходы из первого слоя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9996,  0.9999, -1.0000,  1.0000, -0.6472,  1.0000, -0.9909,  0.8478,\n",
       "        -1.0000,  1.0000, -0.9584,  0.9893, -0.9100, -0.9996, -1.0000, -1.0000,\n",
       "        -0.9999, -1.0000,  1.0000, -0.9648, -0.6903,  0.9627,  0.9999,  0.9999,\n",
       "         1.0000,  1.0000, -0.9813, -0.9998, -1.0000,  1.0000,  0.9821, -1.0000,\n",
       "        -0.7452, -0.9001,  1.0000, -1.0000, -0.9987,  1.0000,  0.9998, -0.9999,\n",
       "        -1.0000, -1.0000,  0.9946,  1.0000,  0.8181,  0.9949, -0.4885, -1.0000,\n",
       "        -1.0000,  0.9996, -0.9820, -1.0000,  0.9273, -1.0000, -0.7985,  1.0000,\n",
       "         0.9984,  0.9994, -1.0000, -1.0000, -1.0000, -0.9832,  1.0000,  1.0000,\n",
       "        -0.9995, -1.0000,  0.9743,  1.0000,  1.0000,  0.9997,  1.0000, -0.9997,\n",
       "        -0.7154, -1.0000,  1.0000, -1.0000, -0.8156, -1.0000,  1.0000,  0.2244,\n",
       "         1.0000,  1.0000,  0.9784,  0.9963, -1.0000,  0.9795, -0.8716,  1.0000,\n",
       "        -1.0000,  1.0000, -1.0000,  0.9678, -1.0000,  0.8436,  0.8159, -1.0000,\n",
       "         0.9996,  0.7441, -0.8775, -0.9998,  0.9967, -0.1164, -1.0000, -0.0561,\n",
       "         1.0000,  1.0000,  0.9997,  0.5745, -0.9480, -0.9998,  0.7597, -1.0000,\n",
       "         0.9998,  1.0000, -0.1100, -1.0000, -0.9991,  0.9947, -0.9914, -0.0953,\n",
       "        -1.0000, -1.0000, -0.9999, -1.0000, -0.9990, -1.0000,  0.7605,  0.6487],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_act[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(h_act.flatten().tolist(), 20, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Это тот самый \"vanishing gradient\", о котором мы ещё услышим позже, когда будем говорить про рекуррентные сети -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на масштаб проблемы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1516213c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 20))\n",
    "plt.imshow(h_act.abs() > 0.99, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиент будет уничтожен везде, где у нас белый пиксел.\n",
    "\n",
    "А если найдётся целиком белый столбец?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Ответ: мы получим \"мёртвый нейрон\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Упражнение**: Вернёмся в `__init__` модели и подберём стандартное отклонение для `w1`, которое даст нам красивое значение для гистограммы активаций (+- равномерно на интервале (-1, 1) с небольшими пиками около границ интервала) и картинку для активаций батча, где будет совсем немного белых пикселей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. А как правильно?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что происходит с распределением значений, когда мы перемножаем две матрицы, инициализированные стандартным нормальным распределением:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0068) tensor(1.0001)\n",
      "tensor(0.0010) tensor(1.0086)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.randn(1000, 10)\n",
    "w = torch.randn(10, 200) / 10**0.5\n",
    "y =  x @ w\n",
    "print(x.mean(), x.std())\n",
    "print(y.mean(), y.std())\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 3))\n",
    "ax1.hist(x.flatten().tolist(), 20, density=True)\n",
    "ax2.hist(y.flatten().tolist(), 20, density=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение расползлось, как исправить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ответ: Оказывается, нужно разделить на $\\sqrt{d_{input}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Упражнение**: какое распределение имеет $Y = X \\cdot W$, где $X \\in \\mathbb{R}^{m \\times k}$, $W \\in \\mathbb{R}^{k \\times n}$ и $X_{ij}, W_{ij} \\sim \\mathcal{N}(0, 1)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике этого достаточно, но если хочется предельной точности: https://pytorch.org/docs/stable/nn.init.html\n",
    "   $$\\text{std} = \\frac{\\text{gain}(f_{act})}{\\sqrt{\\text{fan mode}}}$$\n",
    "\n",
    "Пример статьи с обоснованием для ReLU и PReLU:\n",
    "\n",
    "[Kaiming He et al. Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1473139127471974"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.calculate_gain('tanh') / hidden_dim**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, есть ли проблемы с встроенным слоем `torch.nn.Linear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.l2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # torch.nn.init.kaiming_normal_(self.l1.weight, nonlinearity='tanh')\n",
    "        # torch.nn.init.uniform_(self.l1.bias, -1, 1)\n",
    "        # torch.nn.init.kaiming_normal_(self.l2.weight, nonlinearity='linear')\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
    "        h = self.l1(x.flatten(1))\n",
    "        h_act = F.tanh(h)\n",
    "        logits = self.l2(h_act)\n",
    "        return logits, h_act, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 2.3116\n",
      "Epoch 0 loss = 1.1166\n",
      "Epoch 1 loss = 0.5111\n",
      "Epoch 2 loss = 0.4220\n",
      "Epoch 3 loss = 0.3741\n",
      "Epoch 4 loss = 0.3784\n",
      "Epoch 5 loss = 0.3524\n",
      "Epoch 6 loss = 0.3013\n",
      "Epoch 7 loss = 0.3255\n",
      "Epoch 8 loss = 0.3155\n",
      "Epoch 9 loss = 0.3043\n",
      "Test loss: 0.3521\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "x, y = next(iter(train_loader))\n",
    "# создадим модель и выведем значение ошибки после инициализации\n",
    "model = MLP(input_dim, hidden_dim, output_dim)\n",
    "logits, h_act, h = model(x)\n",
    "loss = F.cross_entropy(logits, y)\n",
    "print(f\"Initial loss: {loss:.4f}\")\n",
    "\n",
    "n_epochs = 10\n",
    "batches_per_epoch = 100\n",
    "for i in range(n_epochs):\n",
    "    loss = train_epoch(train_loader, model, lr=0.1, max_batches=batches_per_epoch)\n",
    "    print(f\"Epoch {i} loss = {loss:.4f}\")\n",
    "\n",
    "print(f\"Test loss: {test_epoch(test_loader, model, max_batches=batches_per_epoch):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Явных проблем нет: инициализация по умолчанию настроена хорошо (и мы можем посмотреть, как именно)\n",
    "\n",
    "Попробуем сделать ещё лучше?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Резюме\n",
    "1. Проблемы с внутренними активациями возникают не только на инициализации, но и в процессе оптимизации - один большой шаг в неправильную сторону может убить нейрон (в случае с ReLU - навсегда)\n",
    "2. В маленьких моделях проблемы инициализации не так критичны - сеть в итоге обучится, просто потребуется больше времени.\n",
    "3. Чем глубже сеть (больше слоёв) - тем больше проблем\n",
    "4. В последние годы добавилось много трюков, которые сделали инициализацию менее критичной:\n",
    "   1. residual connections\n",
    "   2. normalization layers (batch, layer, group)\n",
    "   3. лучшие оптимизаторы (RMSProp, Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Нормализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ioffe, Szegedy (2015). Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотим, чтобы активации не были ни слишком малыми, ни слишком большими, и были близки к стандартному нормальному распределению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея: а давайте просто возьмём активации в батче, вычтем среднее и поделим на стандартное отклонение!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://kharshit.github.io/img/batch_normalization.png\" style=\"background:white\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой ценой? Теперь значение активаций для одного примера уже не детерминировано - оно зависит также от других примеров в батче, который формируется случайным образом. \n",
    "\n",
    "Внезапно, это не так уж плохо: мы учим сеть быть устойчивой к небольшим вариациям входных данных.\n",
    "\n",
    "Но как теперь получать предсказания для одного изолированного примера?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея: копить статистику на обучении, на предсказании использовать её.\n",
    "\n",
    "То есть впервые у нас поведение модели на обучении и валидации отличается!\n",
    "\n",
    "Поэтому для `torch.nn.Module` определено поле `training: bool`, которое указывает, в каком состоянии находится модуль.\n",
    "\n",
    "Переключение: `model.train()` $\\leftrightarrow$ `model.eval()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.l2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.running_mean = torch.zeros(hidden_dim)\n",
    "        self.running_std = torch.ones(hidden_dim)\n",
    "\n",
    "        self.bn_gain = nn.Parameter(torch.ones(hidden_dim), requires_grad=True)\n",
    "        self.bn_shift = nn.Parameter(torch.zeros(hidden_dim), requires_grad=True)\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
    "        h = self.l1(x.flatten(1))\n",
    "        mean = h.mean(dim=0)\n",
    "        std = h.std(dim=0)\n",
    "\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = 0.1 * mean + 0.9 * self.running_mean\n",
    "                self.running_std = 0.1 * std + 0.9 * self.running_std\n",
    "        \n",
    "            h = (h - mean) / (std + 1e-5)\n",
    "        else:\n",
    "            h = (h - self.running_mean) / (self.running_std + 1e-5)\n",
    "\n",
    "        h = h * self.bn_gain + self.bn_shift\n",
    "\n",
    "\n",
    "        h_act = F.tanh(h)\n",
    "        logits = self.l2(h_act)\n",
    "        return logits, h_act, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 2.2620\n",
      "Epoch 0 loss = 0.6172\n",
      "Epoch 1 loss = 0.4135\n",
      "Epoch 2 loss = 0.3752\n",
      "Epoch 3 loss = 0.3445\n",
      "Epoch 4 loss = 0.3467\n",
      "Epoch 5 loss = 0.3248\n",
      "Epoch 6 loss = 0.2737\n",
      "Epoch 7 loss = 0.2979\n",
      "Epoch 8 loss = 0.2954\n",
      "Epoch 9 loss = 0.2860\n",
      "Test loss: 0.3140\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "x, y = next(iter(train_loader))\n",
    "# создадим модель и выведем значение ошибки после инициализации\n",
    "model = MLP(input_dim, hidden_dim, output_dim)\n",
    "logits, h_act, h = model(x)\n",
    "loss = F.cross_entropy(logits, y)\n",
    "print(f\"Initial loss: {loss:.4f}\")\n",
    "\n",
    "n_epochs = 10\n",
    "batches_per_epoch = 100\n",
    "for i in range(n_epochs):\n",
    "    loss = train_epoch(train_loader, model, lr=0.1, max_batches=batches_per_epoch)\n",
    "    print(f\"Epoch {i} loss = {loss:.4f}\")\n",
    "\n",
    "model.eval()  # переводим модель в режим training=False\n",
    "print(f\"Test loss: {test_epoch(test_loader, model, max_batches=batches_per_epoch):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем встроенный `nn.BatchNorm1d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.l1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.l2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
    "        h = self.l1(x.flatten(1))\n",
    "        h = self.bn(h)\n",
    "        h_act = F.tanh(h)\n",
    "        logits = self.l2(h_act)\n",
    "        # помимо логитов, вернём ещё промежуточные активации - они нам понадобятся\n",
    "        return logits, h_act, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 2.2621\n",
      "Epoch 0 loss = 0.6151\n",
      "Epoch 1 loss = 0.4125\n",
      "Epoch 2 loss = 0.3742\n",
      "Epoch 3 loss = 0.3433\n",
      "Epoch 4 loss = 0.3454\n",
      "Epoch 5 loss = 0.3234\n",
      "Epoch 6 loss = 0.2724\n",
      "Epoch 7 loss = 0.2965\n",
      "Epoch 8 loss = 0.2937\n",
      "Epoch 9 loss = 0.2844\n",
      "Test loss: 0.3147\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "x, y = next(iter(train_loader))\n",
    "# создадим модель и выведем значение ошибки после инициализации\n",
    "model = MLP(input_dim, hidden_dim, output_dim)\n",
    "logits, h_act, h = model(x)\n",
    "loss = F.cross_entropy(logits, y)\n",
    "print(f\"Initial loss: {loss:.4f}\")\n",
    "\n",
    "n_epochs = 10\n",
    "batches_per_epoch = 100\n",
    "for i in range(n_epochs):\n",
    "    loss = train_epoch(train_loader, model, lr=0.1, max_batches=batches_per_epoch)\n",
    "    print(f\"Epoch {i} loss = {loss:.4f}\")\n",
    "\n",
    "model.eval()\n",
    "print(f\"Test loss: {test_epoch(test_loader, model, max_batches=batches_per_epoch):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
