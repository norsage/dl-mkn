{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2seq для машинного перевода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "План на сегодня:\n",
    "1. Токенизация текста: byte-pair encoding, sentencepiece\n",
    "2. Encoder-decoder модель для перевода с немецкого на английский\n",
    "3. Добавляем механизм внимания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install datasets transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import T5Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Готовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"bentrevett/multi30k\", split=\"train\")\n",
    "test_dataset = load_dataset(\"bentrevett/multi30k\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def length_histogram(dataset, ax, bins=20) -> None:\n",
    "    en_lengths = []\n",
    "    de_lengths = []\n",
    "    for sample in dataset:\n",
    "        en_lengths.append(len(sample[\"en\"].split(\" \")))\n",
    "        de_lengths.append(len(sample[\"de\"].split(\" \")))\n",
    "\n",
    "    ax.hist(en_lengths, alpha=0.5, bins=bins, label=\"en\")\n",
    "    ax.hist(de_lengths, alpha=0.5, bins=bins, label=\"de\")\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "length_histogram(train_dataset, axes[0])\n",
    "length_histogram(test_dataset, axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим только сравнительно короткие предложения, чтобы можно было чему-то научиться за короткое время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 7\n",
    "\n",
    "\n",
    "def filter_dataset(dataset, maxlen: int) -> list[dict[str, str]]:\n",
    "    return [\n",
    "        dataset[i]\n",
    "        for i in range(len(dataset))\n",
    "        if len(dataset[i][\"en\"].split(\" \")) <= maxlen\n",
    "    ]\n",
    "\n",
    "\n",
    "train_filtered = filter_dataset(train_dataset, maxlen)\n",
    "test_filtered = filter_dataset(test_dataset, maxlen)\n",
    "\n",
    "print(len(train_filtered), len(test_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Токенизация: byte-pair encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение:\n",
    "\n",
    "Начинаем со словаря, состоящего из отдельных символов (начальные токены).\n",
    "На каждом шаге:\n",
    "1. Оцениваем частоту всех пар токенов внутри слов, находим самую частую\n",
    "2. Добавляем её в список токенов и в таблицу слияний\n",
    "3. Останавливаемся, когда достигаем максимального размера словаря\n",
    "\n",
    "\n",
    "Применение:\n",
    "\n",
    "1. Разбиваем текст на символы\n",
    "2. Находим первое возможное слияние в таблице и применяем его\n",
    "3. Останавливаемся, когда дальнейшие слияния невозможны\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://lena-voita.github.io/resources/lectures/seq2seq/bpe/build_merge_table.gif\" style=\"background:white\" height=\"300\"/>\n",
    "<img src=\"https://lena-voita.github.io/resources/lectures/seq2seq/bpe/bpe_apply.gif\" style=\"background:white\" height=\"300\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализаций много, мы будем использовать токенизатор  из библиотеки `transformers`, где помимо самого подготовленного токенизатора (`sentencepiece.SentencePieceProcessor`) много полезных методов для кодирования и декодирования.\n",
    "\n",
    "Добавим при создании новый токен, который будет указывать на начало перевода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer: T5Tokenizer = T5Tokenizer.from_pretrained(\n",
    "    \"t5-small\", padding_size=\"right\", bos_token=\"</b>\", legacy=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Размер словаря: \", len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_german = tokenizer.encode(train_dataset[0][\"de\"])\n",
    "encoded_english = tokenizer.encode(train_dataset[0][\"en\"])\n",
    "print(encoded_german)\n",
    "print(tokenizer.decode(encoded_german))\n",
    "print(encoded_english)\n",
    "print(tokenizer.decode(encoded_english))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Об упаковке в батчи можно больше не беспокоиться - токенизатор умеет обрабатывать сразу пачку примеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [train_dataset[i][\"en\"] for i in range(4)]\n",
    "\n",
    "encoded_batch = tokenizer.batch_encode_plus(\n",
    "    batch, padding=\"longest\", return_tensors=\"pt\"\n",
    ")\n",
    "print(encoded_batch[\"input_ids\"].shape)\n",
    "print(encoded_batch.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возвращается два значения: `input_ids` - это наши токены, а `attention_mask` - это тензор, равный по размеру батчу токенов, где на месте `pad_token` стоят нули, в остальных позициях - единицы. Это нам понадобится потом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А ещё можно кодировать сразу входные и выходные данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [train_dataset[i][\"en\"] + tokenizer.bos_token for i in range(4)]\n",
    "targets = [train_dataset[i][\"de\"] for i in range(4)]\n",
    "\n",
    "encoded_batch = tokenizer(\n",
    "    inputs, text_target=targets, padding=\"longest\", return_tensors=\"pt\"\n",
    ")\n",
    "print(encoded_batch.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем это в `collate_fn` для сборки батчей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(\n",
    "    tokenizer: T5Tokenizer, batch: list[tuple[str, str]]\n",
    ") -> tuple[Tensor, Tensor]:\n",
    "    prompt = tokenizer.bos_token\n",
    "    inputs, targets = zip(*[(pair[\"de\"], prompt + pair[\"en\"]) for pair in batch])\n",
    "    encoded_batch = tokenizer(\n",
    "        inputs, text_target=targets, padding=\"longest\", return_tensors=\"pt\"\n",
    "    )\n",
    "    return encoded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [train_dataset[i] for i in range(4)]\n",
    "encoded_batch = collate_fn(tokenizer, batch)\n",
    "print(encoded_batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoded_batch[\"input_ids\"].shape)\n",
    "print(encoded_batch[\"attention_mask\"].shape)\n",
    "print(encoded_batch[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всё готово для получения минибатчей из датасетов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_filtered,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda batch: collate_fn(tokenizer, batch),\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_filtered,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda batch: collate_fn(tokenizer, batch),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Encoder-decoder модель для перевода на рекуррентных сетях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://esciencegroup.files.wordpress.com/2016/03/seq2seq.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем энкодер, который будет возвращать последнее состояние"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size: int, hidden_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.rnn = nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, source: Tensor) -> Tensor:\n",
    "        h = self.embedding(source)\n",
    "        h, _ = self.rnn(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_size=len(tokenizer), hidden_dim=128)\n",
    "h = encoder.forward(batch[\"input_ids\"])\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Декодер использует это состояние в качестве собственного начального:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size: int, hidden_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.rnn = nn.GRUCell(hidden_dim, hidden_dim)\n",
    "        self.lm_head = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def _get_last_encoder_state(\n",
    "        self, encoder_states: Tensor, attention_mask: Tensor\n",
    "    ) -> Tensor:\n",
    "        B, T, _ = encoder_states.shape\n",
    "        last_idx = attention_mask.sum(dim=-1) - 1\n",
    "        return encoder_states[torch.arange(B), last_idx]\n",
    "\n",
    "    def forward(\n",
    "        self, encoder_states: Tensor, attention_mask: Tensor, target: Tensor\n",
    "    ) -> Tensor:\n",
    "        B, T = target.shape\n",
    "\n",
    "        embeds = F.relu(self.embedding(target))\n",
    "        h = self._get_last_encoder_state(encoder_states, attention_mask)\n",
    "        logits = []\n",
    "        for t in range(T):\n",
    "            h = self.rnn.forward(embeds[:, t], h)\n",
    "            logits.append(self.lm_head.forward(h))\n",
    "\n",
    "        return torch.stack(logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_size=len(tokenizer), hidden_dim=128)\n",
    "logits = decoder.forward(h, batch[\"attention_mask\"], batch[\"labels\"])\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем обучить:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT, OptimizerLRScheduler\n",
    "\n",
    "\n",
    "class Seq2Seq(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder: Encoder,\n",
    "        decoder: Decoder,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        lr: float = 0.01,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.tokenizer = tokenizer\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, source: Tensor, attention_mask: Tensor, target: Tensor) -> Tensor:\n",
    "        h = self.encoder.forward(source)\n",
    "        logits = self.decoder.forward(h, attention_mask, target)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch: dict[str, Tensor], batch_idx: int) -> STEP_OUTPUT:\n",
    "        logits = self.forward(\n",
    "            batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"labels\"]\n",
    "        )\n",
    "        loss = F.cross_entropy(\n",
    "            logits[:, :-1].reshape(-1, len(self.tokenizer)),\n",
    "            batch[\"labels\"][:, 1:].flatten(),\n",
    "            ignore_index=self.tokenizer.pad_token_id,\n",
    "        )\n",
    "        self.log(\"loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def translate(\n",
    "        self,\n",
    "        input_ids: Tensor,\n",
    "        attention_mask: Tensor,\n",
    "        bos_token_id: int,\n",
    "        max_new_tokens: int = 20,\n",
    "    ) -> Tensor:\n",
    "        h = self.encoder.forward(input_ids)\n",
    "        idx = torch.full((input_ids.shape[0], 1), fill_value=bos_token_id)\n",
    "\n",
    "        for t in range(max_new_tokens):\n",
    "            logits = self.decoder.forward(h, attention_mask, idx)[:, -1]\n",
    "            new_token = logits.argmax(dim=-1, keepdim=True)\n",
    "            idx = torch.cat([idx, new_token], dim=1)\n",
    "\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(accelerator=\"cpu\", max_epochs=5)\n",
    "encoder = Encoder(vocab_size=len(tokenizer), hidden_dim=128)\n",
    "decoder = Decoder(vocab_size=len(tokenizer), hidden_dim=128)\n",
    "seq2seq = Seq2Seq(encoder, decoder, tokenizer)\n",
    "trainer.fit(model=seq2seq, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_batch(batch: dict[str, Tensor], model: Seq2Seq, tokenizer: T5Tokenizer):\n",
    "    source = batch[\"input_ids\"]\n",
    "    target = batch[\"labels\"]\n",
    "\n",
    "    preds = model.translate(\n",
    "        source, batch[\"attention_mask\"], tokenizer.bos_token_id, max_new_tokens=20\n",
    "    )\n",
    "\n",
    "    # decode\n",
    "\n",
    "    source, target, preds = map(\n",
    "        lambda x: tokenizer.batch_decode(x, skip_special_tokens=True),\n",
    "        (source, target, preds),\n",
    "    )\n",
    "\n",
    "    for src, tgt, pred in zip(source, target, preds):\n",
    "        print(f\"Deutsch: {src}\")\n",
    "        print(f\"English: {tgt}\")\n",
    "        print(f\"Translation: {pred}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_batch(next(iter(train_loader)), seq2seq, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attetion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://i.imgur.com/6fKHlHb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем слой аддитивного внимания\n",
    "\n",
    "На вход: последовательность состояний энкодера $h_0^e, h_1^e, ..., h_T^e$ и текущее состояние декодера $h^d$\n",
    "\n",
    "1. получим логиты для весов внимания с помощью двуслойного перцептрона: $$a_t = \\psi(\\tanh(\\phi_e(h_t^e) + \\phi_d(h_d)))$$\n",
    "2. рассчитываем вероятности $$ p_t = {{e ^ {a_t}} \\over { \\sum_\\tau e^{a_\\tau} }} $$\n",
    "3. считаем вектор контекста как взвешенную сумму состояний энкодера \n",
    "$$ c = \\sum_t p_t \\cdot h^e_t $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        ...\n",
    "\n",
    "    def forward(\n",
    "        self, encoder_states: Tensor, attention_mask: Tensor, decoder_states: Tensor\n",
    "    ) -> Tensor:\n",
    "        B, T, d = encoder_states.shape\n",
    "\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь модифицируем наш декодер для использования механизма внимания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderWithAttention(nn.Module):\n",
    "    def __init__(self, vocab_size: int, hidden_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.rnn = nn.GRUCell(hidden_dim, hidden_dim)\n",
    "        self.lm_head = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def _get_last_encoder_state(\n",
    "        self, encoder_states: Tensor, attention_mask: Tensor\n",
    "    ) -> Tensor:\n",
    "        B, T, _ = encoder_states.shape\n",
    "        last_idx = attention_mask.sum(dim=-1) - 1\n",
    "        return encoder_states[torch.arange(B), last_idx]\n",
    "\n",
    "    def forward(\n",
    "        self, encoder_states: Tensor, attention_mask: Tensor, target: Tensor\n",
    "    ) -> Tensor:\n",
    "        B, T = target.shape\n",
    "\n",
    "        embeds = F.relu(self.embedding(target))\n",
    "        h = self._get_last_encoder_state(encoder_states, attention_mask)\n",
    "        logits = []\n",
    "        for t in range(T):\n",
    "            h = self.rnn.forward(embeds[:, t], h)\n",
    "            logits.append(self.lm_head.forward(h))\n",
    "\n",
    "        return torch.stack(logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_size=len(tokenizer), hidden_dim=128)\n",
    "decoder = DecoderWithAttention(vocab_size=len(tokenizer), hidden_dim=128)\n",
    "seq2seq_attention = Seq2Seq(encoder, decoder, tokenizer)\n",
    "print(\n",
    "    seq2seq_attention.forward(\n",
    "        batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"labels\"]\n",
    "    ).shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(accelerator=\"cpu\", max_epochs=5)\n",
    "trainer.fit(model=seq2seq_attention, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_batch(next(iter(train_loader)), seq2seq_attention, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
